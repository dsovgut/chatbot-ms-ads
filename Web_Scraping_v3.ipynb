{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881863a1-a8cf-4f71-a9c5-8bf16851ca45",
   "metadata": {},
   "source": [
    "### UChicago MS-ADS program web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63668f9f-41f4-4b0a-8491-14c6dd1cca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import urljoin, urldefrag\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import html\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4acc45-187b-4a32-9ade-0e79bcccb968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/in-person-program/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/online-program/%20\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/online-program/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/capstone-projects/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/course-progressions/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/how-to-apply/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/events-deadlines/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/our-students/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/faqs/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/career-outcomes/\n",
      "Scraping https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/tuition-fees-aid/\n",
      "Saved 315 text chunks.\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\"\n",
    "visited = set() #Queue of links to visit\n",
    "urls_to_visit = [BASE_URL]\n",
    "documents = []\n",
    "\n",
    "def setup_selenium(): #use Selenium to render pages\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return html.unescape(text)\n",
    "\n",
    "def extract_tabs_accordions(soup, url, page_title): #Extract information stored in tabs and accordions such as courses\n",
    "    entries = []\n",
    "    tabs = soup.select('ul.tabs > li.tabs-title > a')\n",
    "    for tab in tabs:\n",
    "        tab_name = tab.get_text(strip=True)\n",
    "        tab_id = tab.get('href', '').lstrip('#')\n",
    "        tab_panel = soup.find('div', id=tab_id)\n",
    "        if not tab_panel:\n",
    "            continue\n",
    "\n",
    "        accordion_items = tab_panel.select('ul.accordion li.accordion__item')\n",
    "        for item in accordion_items:\n",
    "            title_tag = item.select_one('a.accordion-title')\n",
    "            desc_tag = item.select_one('div.accordion__content div.textblock')\n",
    "            if title_tag and desc_tag:\n",
    "                title = clean_text(title_tag.get_text())\n",
    "                description = clean_text(desc_tag.get_text())\n",
    "                entries.append({\n",
    "                    \"url\": url,\n",
    "                    \"section\": tab_name,\n",
    "                    \"title\": title,\n",
    "                    \"text\": f\"{description}\"\n",
    "                })\n",
    "    return entries\n",
    "\n",
    "def extract_text_sections(soup, url, page_title): #Extract main content in sections\n",
    "    for tab_block in soup.select(\".tabs-content\"):\n",
    "        tab_block.decompose()\n",
    "\n",
    "    sections = []\n",
    "    current_heading = None\n",
    "    current_text = []\n",
    "\n",
    "    root = soup.find(\"main\") or soup.body\n",
    "\n",
    "    for tag in root.descendants:\n",
    "        if isinstance(tag, Tag):\n",
    "            if tag.name in ['h2', 'h3']:\n",
    "                if current_heading or current_text:\n",
    "                    section_text = clean_text(' '.join(current_text))\n",
    "                    if section_text:\n",
    "                        sections.append({\n",
    "                            \"url\": url,\n",
    "                            \"section\": page_title,\n",
    "                            \"title\":current_heading,\n",
    "                            \"text\": f\"{section_text}\"\n",
    "                        })\n",
    "                    current_text = []\n",
    "                current_heading = clean_text(tag.get_text())\n",
    "\n",
    "            elif tag.name == 'p':\n",
    "                text = clean_text(tag.get_text())\n",
    "                if text:\n",
    "                    current_text.append(text)\n",
    "\n",
    "    if current_heading or current_text:\n",
    "        section_text = clean_text(' '.join(current_text))\n",
    "        if section_text:\n",
    "            sections.append({\n",
    "                \"url\": url,\n",
    "                \"section\": page_title,\n",
    "                \"title\":current_heading,\n",
    "                \"text\": f\"{section_text}\"\n",
    "            })\n",
    "\n",
    "    return sections\n",
    "    \n",
    "def extract_people_profiles(soup, url, page_title): #Extract faculty profiles that are stored in gridder list\n",
    "    people = []\n",
    "    person_blocks = soup.select('div.gridder-content')\n",
    "\n",
    "    for person in person_blocks:\n",
    "        person_id = person.get('id', '')\n",
    "        name = ' '.join(part.capitalize() for part in person_id.replace('-', ' ').split()) if person_id else \"N/A\"\n",
    "\n",
    "        bio = person.select(\"div.textblock p\")\n",
    "        description = ' '.join(clean_text(p.get_text()) for p in bio if p.get_text(strip=True))\n",
    "\n",
    "        if description:\n",
    "            people.append({\n",
    "                \"url\": url,\n",
    "                \"section\":page_title,\n",
    "                \"title\":name,\n",
    "                \"text\": f\"{description}\"\n",
    "            })\n",
    "    return people\n",
    "\n",
    "def main():\n",
    "    driver = setup_selenium()\n",
    "\n",
    "    while urls_to_visit:\n",
    "        url = urls_to_visit.pop(0)\n",
    "        if url in visited:\n",
    "            continue\n",
    "\n",
    "        print(f\"Scraping {url}\")\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            page_html = driver.page_source\n",
    "            soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "            visited.add(url)\n",
    "\n",
    "            page_title = soup.title.string.strip() if soup.title else 'Untitled Page'\n",
    "            #Extract information from different structures\n",
    "            tab_data = extract_tabs_accordions(soup, url, page_title)\n",
    "            people_data = extract_people_profiles(soup, url, page_title)\n",
    "            section_data = extract_text_sections(soup, url, page_title)\n",
    "\n",
    "            documents.extend(tab_data)\n",
    "            documents.extend(section_data)\n",
    "            documents.extend(people_data)\n",
    "\n",
    "            # Get more sublinks to visit\n",
    "            for a_tag in soup.find_all(\"a\", href=True):\n",
    "                href = a_tag['href']\n",
    "                full_url = urljoin(url, href)\n",
    "                full_url, _ = urldefrag(full_url)  # Remove #fragments to avoid redundant urls\n",
    "\n",
    "                if full_url.startswith(BASE_URL) and full_url not in visited and full_url not in urls_to_visit: #Only look at univisited sublinks for the program\n",
    "                    urls_to_visit.append(full_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    section_title_map = defaultdict(list)\n",
    "\n",
    "    for doc in documents:\n",
    "        section = doc[\"section\"]\n",
    "        title = doc[\"title\"]\n",
    "        if title:\n",
    "            section_title_map[section].append(title)\n",
    "\n",
    "    # Create one summary row per section\n",
    "    summary_rows = []\n",
    "    for section, titles in section_title_map.items():\n",
    "        summary_text = \"\\n\".join(f\", {t}\" for t in titles)\n",
    "        summary_rows.append({\n",
    "            \"url\": \"\",  # Optional: set this to a representative URL if needed\n",
    "            \"section\": section,\n",
    "            \"title\": section,\n",
    "            \"text\": f\"{summary_text}\"\n",
    "        })\n",
    "\n",
    "    # Add summaries to the documents list\n",
    "    documents.extend(summary_rows)\n",
    "\n",
    "    # Save data to JSON\n",
    "    with open(\"uchicago_msads_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(documents, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Saved {len(documents)} text chunks.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad82a0e-2400-4742-b404-419e10a42145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
